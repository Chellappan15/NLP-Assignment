from collections import Counter, defaultdict
import nltk
from nltk.util import ngrams
import random

nltk.download('punkt')

# Sample text corpus
text_data = "This is a sample text corpus. This corpus is used to demonstrate text processing."

# Tokenize the text into words
word_tokens = nltk.word_tokenize(text_data.lower())

# Unigrams
word_counts = Counter(word_tokens)
print("Unigrams:", word_counts)

# Bigrams
two_grams = list(ngrams(word_tokens, 2))
two_gram_counts = Counter(two_grams)
print("\nBigrams:", two_gram_counts)

# Trigrams
three_grams = list(ngrams(word_tokens, 3))
three_gram_counts = Counter(three_grams)
print("\nTrigrams:", three_gram_counts)

# Bigram probabilities
two_gram_probabilities = defaultdict(lambda: defaultdict(int))
for first_word, second_word in two_grams:
    two_gram_probabilities[first_word][second_word] += 1

for first_word in two_gram_probabilities:
    total_count = float(sum(two_gram_probabilities[first_word].values()))
    for second_word in two_gram_probabilities[first_word]:
        two_gram_probabilities[first_word][second_word] /= total_count

print("\nBigram Probabilities:")
for first_word in two_gram_probabilities:
    for second_word in two_gram_probabilities[first_word]:
        print(f"P({second_word}|{first_word}) = {two_gram_probabilities[first_word][second_word]}")

# Next word prediction function
def predict_next(word, num_suggestions=3):
    if word in two_gram_probabilities:
        sorted_predictions = sorted(two_gram_probabilities[word].items(), key=lambda item: item[1], reverse=True)
        return [next_word for next_word, prob in sorted_predictions[:num_suggestions]]
    else:
        return []

# Example: Predict next words for 'this'
suggested_words = predict_next('this')
print("\nNext word predictions for 'this':", suggested_words)
